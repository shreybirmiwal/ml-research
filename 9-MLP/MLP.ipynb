{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "29d44168-3480-4018-9d42-e2fd5b2a8c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'of', 'and', 'to', 'a', 'in', 'for', 'is', 'on', 'that']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "words = []\n",
    "with open(\"google-10000-english-no-swears.txt\", 'r') as file:\n",
    "    words = file.read().splitlines()\n",
    "    \n",
    "print(words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c577368a-8965-4ee8-819b-0a24fbdb9e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSplitData(words):\n",
    "    \n",
    "    xs = []\n",
    "    ys = []\n",
    "    \n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        word = \"{{{\"+word+\"{\"\n",
    "\n",
    "        for i in range(len(word)-3):\n",
    "            #print(word[i], word[i+1], word[i+2], \"-->\", word[i+3])\n",
    "            \n",
    "            x = [ord(word[i])-97, ord(word[i+1])-97, ord(word[i+2])-97]\n",
    "            y = [ord(word[i+3])-97]\n",
    "\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "\n",
    "    # print(xs)\n",
    "    # print(ys)\n",
    "    return (xs, ys)\n",
    "            \n",
    "data = getSplitData([\"ABC\", 'xyz', 'cde'])\n",
    "xs = data[0]\n",
    "ys = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "85295fcc-4f4e-493d-9d34-fb14fe73a873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 3])\n",
      "torch.Size([12, 1])\n"
     ]
    }
   ],
   "source": [
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "print(xs.size())\n",
    "print(ys.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0c8910fd-fb08-4d5e-85db-0341324f9ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 3, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8605, -0.2473],\n",
       "         [-0.8605, -0.2473],\n",
       "         [-0.8605, -0.2473]],\n",
       "\n",
       "        [[-0.8605, -0.2473],\n",
       "         [-0.8605, -0.2473],\n",
       "         [-0.1147,  0.0956]],\n",
       "\n",
       "        [[-0.8605, -0.2473],\n",
       "         [-0.1147,  0.0956],\n",
       "         [ 1.1135, -0.7825]],\n",
       "\n",
       "        [[-0.1147,  0.0956],\n",
       "         [ 1.1135, -0.7825],\n",
       "         [ 0.7955, -0.0201]],\n",
       "\n",
       "        [[-0.8605, -0.2473],\n",
       "         [-0.8605, -0.2473],\n",
       "         [-0.8605, -0.2473]],\n",
       "\n",
       "        [[-0.8605, -0.2473],\n",
       "         [-0.8605, -0.2473],\n",
       "         [ 0.9180, -0.8643]],\n",
       "\n",
       "        [[-0.8605, -0.2473],\n",
       "         [ 0.9180, -0.8643],\n",
       "         [ 0.3537,  1.1661]],\n",
       "\n",
       "        [[ 0.9180, -0.8643],\n",
       "         [ 0.3537,  1.1661],\n",
       "         [ 1.0545, -2.0348]],\n",
       "\n",
       "        [[-0.8605, -0.2473],\n",
       "         [-0.8605, -0.2473],\n",
       "         [-0.8605, -0.2473]],\n",
       "\n",
       "        [[-0.8605, -0.2473],\n",
       "         [-0.8605, -0.2473],\n",
       "         [ 0.7955, -0.0201]],\n",
       "\n",
       "        [[-0.8605, -0.2473],\n",
       "         [ 0.7955, -0.0201],\n",
       "         [ 0.9674, -1.0114]],\n",
       "\n",
       "        [[ 0.7955, -0.0201],\n",
       "         [ 0.9674, -1.0114],\n",
       "         [ 1.0219, -1.6888]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making the embedding lookup table\n",
    "embedding_table = torch.randn(27, 2)\n",
    "embedded_data = embedding_table[xs] #look up  for each xs find embedding\n",
    "print(embedded_data.size())\n",
    "embedded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aef2543a-ec3d-4cbb-a6b4-43e52d23d961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8605, -0.2473, -0.8605, -0.2473, -0.8605, -0.2473],\n",
       "        [-0.8605, -0.2473, -0.8605, -0.2473, -0.1147,  0.0956],\n",
       "        [-0.8605, -0.2473, -0.1147,  0.0956,  1.1135, -0.7825],\n",
       "        [-0.1147,  0.0956,  1.1135, -0.7825,  0.7955, -0.0201],\n",
       "        [-0.8605, -0.2473, -0.8605, -0.2473, -0.8605, -0.2473],\n",
       "        [-0.8605, -0.2473, -0.8605, -0.2473,  0.9180, -0.8643],\n",
       "        [-0.8605, -0.2473,  0.9180, -0.8643,  0.3537,  1.1661],\n",
       "        [ 0.9180, -0.8643,  0.3537,  1.1661,  1.0545, -2.0348],\n",
       "        [-0.8605, -0.2473, -0.8605, -0.2473, -0.8605, -0.2473],\n",
       "        [-0.8605, -0.2473, -0.8605, -0.2473,  0.7955, -0.0201],\n",
       "        [-0.8605, -0.2473,  0.7955, -0.0201,  0.9674, -1.0114],\n",
       "        [ 0.7955, -0.0201,  0.9674, -1.0114,  1.0219, -1.6888]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape is screwed up , lets fix it\n",
    "embedded_data = embedded_data.view(embedded_data.shape[0], 6)\n",
    "print(embedded_data.size())\n",
    "embedded_data\n",
    "\n",
    "#12 examples of 3 inputs each. each input has <x,y> on embedding table so 12 examples of 6 inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d428d5a7-e599-4d64-a0c2-61a391c8db53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tan layer 1 torch.Size([12, 100])\n",
      "Layer 2 torch.Size([12, 27])\n"
     ]
    }
   ],
   "source": [
    "# 1. first we vector embbed\n",
    "# 2. then we do first layer and bias\n",
    "# 3. then we tanh\n",
    "# 4. then we do 2nd layer and bias and shrink down to just 27 outputs\n",
    "# 5. then we softmax \n",
    "# 6. then we get loss \n",
    "\n",
    "#tunable params: embedding_table, w1, b1, w2, b2\n",
    "\n",
    "W1 = torch.randn((6, 100), requires_grad=True)\n",
    "B1 = torch.randn((100), requires_grad=True)\n",
    "\n",
    "layer1 = embedded_data @ W1 + B1\n",
    "tan_layer1 = torch.tanh(layer1)\n",
    "print(\"Tan layer 1\", tan_layer1.size())\n",
    "\n",
    "W2 = torch.randn((100, 27), requires_grad=True)\n",
    "B2 = torch.randn((27), requires_grad=True)\n",
    "layer2 = tan_layer1 @ W2 + B2\n",
    "\n",
    "print(\"Layer 2\", layer2.size())\n",
    "\n",
    "\n",
    "#softmax to do the loss: But remember, this is the same as cross-entropy-loss: which is actually more efficient cuz pytorch implemntaiton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b66e20-3341-4ca0-95f1-c25af1b0071b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
